{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "### install ###\n",
    "###############\n",
    "'''\n",
    "pip install pandas\n",
    "pip install xlrd\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "### cleaning of city data, deletion of duplicate city data ###\n",
    "##############################################################\n",
    "\n",
    "import pandas as pd\n",
    "dfcity = pd.read_csv('worldcities.csv')              #Reading the csv file and storing it in a dataframe called dfcity\n",
    "\n",
    "i = 0                                                    #i and e are the indexes of the cities in the dataframe dfcity\n",
    "e = 0\n",
    "to_drop = []                                             #creation of an empty list\n",
    "\n",
    "for city in dfcity['city']:\n",
    "    for city2 in dfcity['city']:\n",
    "        if city == city2 :                               #Comparing the city names in the dataframe dfcity\n",
    "            if i != e :                                  #if the index of the 2 citie with the same name is different\n",
    "                pope = dfcity.population[e]\n",
    "                popi = dfcity.population[i]\n",
    "                \n",
    "                if pope > popi:   \n",
    "                    to_drop.append(i)                    #for these 2 cities with the same name we add the index of the city with the least population to the list \n",
    "                    \n",
    "                elif popi>pope:\n",
    "                    to_drop.append(e)                     #for these 2 cities with the same name we add the index of the city with the least population to the list \n",
    "                    \n",
    "        e += 1                                             #add 1 to e to keep the index updated\n",
    "    i += 1                                                 #add 1 to i to keep the index updated\n",
    "    e = 0                                                  #reset the index to 0 as the loop starts again\n",
    "\n",
    "\n",
    "\n",
    "to_drop = list(set(to_drop))                               #many cities in the world have the same name so we delete duplicate elements\n",
    "to_drop.sort()                                             #It sorts the list in ascending order\n",
    "\n",
    "\n",
    "for i in (to_drop):\n",
    "    dfcity=dfcity.drop(i)                                  #Dropping the cities with the same name and the least population.\n",
    "\n",
    "dfcity.to_csv('data_city_update.csv')                      #Saving the dataframe dfcity in a csv file called data_city_update.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "### delete tweet lines without location ###\n",
    "###########################################\n",
    "\n",
    "low_memory=False\n",
    "df = pd.read_csv('data_twitter_api.csv',engine='python', error_bad_lines=False)   #reading of the two dataset, data with tweet and data of the city\n",
    "dfcity = pd.read_csv('data_city_update.csv')\n",
    "\n",
    "try:                                                                               #Trying to remove the column 'Unnamed: 0' from the dataframe dfcity. If it fails, it will pass. Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "    dfcity.pop('Unnamed: 0')                                                       #Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "except KeyError as err:\n",
    "        pass\n",
    "\n",
    "to_fast=len(df)                                                                    #if the data contains too many tweets we can access it by reducing the data by modifying len(df) by the number of data we want\n",
    "df_fast = df[:to_fast]\n",
    "\n",
    "i=0                                                                                 #The index of the first element \n",
    "\n",
    "while i<len(df_fast):\n",
    "    try :\n",
    "        if ',' in df_fast.user_location[i]:                             \n",
    "            text =df_fast.user_location[i]\n",
    "            head, sep, tail = text.partition(',')\n",
    "            df_fast.user_location[i]=head                                          #Removing the comma and after from the user_location column\n",
    "\n",
    "    except TypeError as err:                                                       #A way to handle the error. If the program encounters a TypeError, it will pass and continue the program\n",
    "        pass\n",
    "\n",
    "    i+=1                                                                           #add 1 to e to keep the index updated\n",
    "\n",
    "\n",
    "e=0                                                                                #The index of the first element \n",
    "twi=[]                                                                             #creation of an empty list\n",
    "\n",
    "for i in df_fast['user_location']:                                                 #loop that will look at each location of user_location in the tweet data set\n",
    "    \n",
    "    for a in dfcity['city']:                                                       #another loop that will look at each location of city in the dataset of the world city\n",
    "        if i == a:                                                                 #check whether the two elements are the same\n",
    "            twi.append(e)                                                          #if yes, we add e (index element) of the line in data set of tweet\n",
    "    e+=1                                                                           #add 1 to e to keep the index updated\n",
    "    \n",
    "twi = list(set(twi))                                                               #many cities in the world have the same name so we delete duplicate elements\n",
    "twi.sort()                                                                         #It sorts the list of index of the tweet with the correct location\n",
    "\n",
    "nb_tweet_in_data = len(twi)-1                                                      #Taking the last index of the list of the index of the tweet with the correct location\n",
    "df_s = df_fast[:twi[nb_tweet_in_data]]\n",
    "\n",
    "to_drop = [ele for ele in range(len(df_s)) if ele not in twi]                      #we take the inverse of the elements to know which are the elements without corect localization in order to remove them from the data\n",
    "to_drop.sort()\n",
    "\n",
    "for i in (to_drop):                                                                #loop that will drop the line without location in the dataset\n",
    "    df_s=df_s.drop(i)\n",
    "    \n",
    "\n",
    "'''\n",
    "with open(\"listTwi.txt\", \"w\") as f:       #Writing the list of the index of the tweet with the correct location in a txt file\n",
    "    for s in twi:\n",
    "        f.write(str(s) +\",\")\n",
    "'''\n",
    "\n",
    "df_s.to_csv('data_5K.csv')                                                          #Saving the dataframe df_s to a csv file called data_5K.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "### Adding the latitude and longitude for each location for each tweet ###\n",
    "##########################################################################\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data_5K.csv')                #Reading the csv file\n",
    "dfcity = pd.read_csv('data_city_update.csv')   #Reading the csv file\n",
    "\n",
    "try:                                           #Trying to remove the column 'Unnamed: 0' from the dataframe dfcity. If it fails, it will pass. Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "    df.pop('Unnamed: 0')\n",
    "except KeyError as err:\n",
    "        pass\n",
    "\n",
    "e=0                                            ##The index of the first element\n",
    "latitude=[]                                    #creation of an empty list which will be used to indicate the latitude assigned to the city of a tweet\n",
    "longitude=[]                                   #creation of an empty list which will be used to indicate the longitude assigned to the city of a tweet\n",
    "\n",
    "\n",
    "for location in df['user_location']:           #This is a loop that is going through the user_location column of the dataframe df\n",
    "    while location != dfcity.city[e]:          #comparing it to the city column of the dataframe dfcity\n",
    "        e+=1                                   #add 1 to e to keep the index updated\n",
    "    latitude.append(dfcity.lat[e])             #if the while loop stops it means that the right city is found, the latitude and longitude of the city is appended to the latitude and longitude list\n",
    "    longitude.append(dfcity.lng[e])\n",
    "    \n",
    "\n",
    "\n",
    "    e=0                                        #reset the index to 0 as the loop starts again\n",
    "    \n",
    "\n",
    "df.insert(6,\"U_latitude\",latitude,True)        #Inserting the latitude and longitude list into the dataframe df at the 6th and 7th column\n",
    "df.insert(7,\"U_longitude\",longitude,True)\n",
    "\n",
    "\n",
    "df.to_csv('data_tweet_with_location.csv')      #Saving the dataframe df into a csv file called tweet_with_location.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "### Converting the date and time from excel format to datetime format ###\n",
    "#########################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "\n",
    "df = pd.read_csv('data_tweet_with_location.csv') \n",
    "\n",
    "try:                                                            #Trying to remove the column 'Unnamed: 0' from the dataframe dfcity. If it fails, it will pass. Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "    df.pop('Unnamed: 0')\n",
    "except KeyError as err:\n",
    "        pass\n",
    "\n",
    "a=0                                                             #The index of the first element\n",
    "while a < len(df):                                              #The above code is converting the date and time from excel format to datetime format\n",
    "    try:\n",
    "        user_created_date = xlrd.xldate_as_datetime(df.user_created[a], 0)\n",
    "        df.user_created[a]=user_created_date\n",
    "        tweet_date = xlrd.xldate_as_datetime(df.date[a], 0)\n",
    "        df.date[a]=tweet_date\n",
    "    except TypeError as err:\n",
    "        pass\n",
    "    \n",
    "    a+=1                                                         #add 1 to e to keep the index updated\n",
    "\n",
    "\n",
    "df.to_csv('data_tweet_with_location_and_date.csv')               #Saving the dataframe df to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "######## extract the hour from the date ##########\n",
    "### extract the tweet link from the tweet text ###\n",
    "##################################################\n",
    "\n",
    "df = pd.read_csv('data_tweet_with_location_and_date.csv') \n",
    "\n",
    "try:                                                    #Trying to remove the column 'Unnamed: 0' from the dataframe dfcity. If it fails, it will pass. Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "    df.pop('Unnamed: 0')\n",
    "except KeyError as err:\n",
    "        pass\n",
    "\n",
    "hour = []                                               #Creating empty lists to store data \n",
    "date = []\n",
    "tweet = []\n",
    "link = []\n",
    "\n",
    "i=0                                                      #The index of the first element\n",
    "while i < len(df):\n",
    "    date_hour =df.date[i]\n",
    "    head, sep, tail = date_hour.partition(' ')          #Splitting the string date_hour into three parts: head wich corespond to the date, sep and tail which corresponds to the hour. The separator is the space ' '\n",
    "    date.append(head)                                   #appends the date to the date list\n",
    "    head, sep, tail=tail.partition('+')                 #It splits the string tail into three parts: head wich corespond to the hour, sep and tail which corresponds to the time zone wich is which is incorrect information. The separator is the '+'\n",
    "    hour.append(head)                                   #It appends the hour to the hour list                         \n",
    "\n",
    "    tw =df.text[i]                                      #Creating a variable tw which is equal to the text of the tweet at the index i\n",
    "    \n",
    "    head, sep, tail = tw.partition('https://t.co/')     #It splits the string tw into three parts: head wich corespond to the text of the tweet, sep and tail which corresponds to the link. The separator is the 'https://t.co/'\n",
    "    \n",
    "    tweet.append(head)                                  #It appends the text of the tweet to the tweet list\n",
    "    \n",
    "    if 'https://t.co/' in tail :                        #Checking if there is stil a link in the tail of the tweet text. If there is this means that there is a link in the tweet before the twitter link of the tweet itself\n",
    "        lk = tail\n",
    "        head, sep, tail = lk.partition('https://t.co/')\n",
    "\n",
    "    link.append(sep+tail)                               #It appends the link to the link list\n",
    "    \n",
    "    i+=1                                                #add 1 to e to keep the index updated\n",
    "\n",
    "\n",
    "\n",
    "df.pop('date')                                          #Removing the column old 'date'\n",
    "df.insert(10,\"date\",date,True)                          #inserting the new columns 'date' and 'hour' from the list at the index 10 and 11\n",
    "df.insert(11,\"hour\",hour,True)\n",
    "df.pop('text')                                          #Removing the column old 'text'\n",
    "df.insert(12,\"tweet\",tweet,True)                        #Inserting the new columns 'tweet' and 'link' from the list at the index 12 and 13\n",
    "df.insert(13,\"link\",link,True)\n",
    "\n",
    "df.to_csv('data_tweet_with_location_and_date_hour.csv')  #Saving the dataframe df into a csv file called 'data_tweet_with_location_and_date_hour.csv'"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
