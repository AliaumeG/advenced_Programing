{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "### install ###\n",
    "###############\n",
    "'''\n",
    "\n",
    "pip install pandas\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "### delete tweet lines without location ###\n",
    "###########################################\n",
    "import pandas as pd\n",
    "\n",
    "low_memory=False\n",
    "df = pd.read_csv('data_twitter_api.csv',engine='python', error_bad_lines=False)   #reading of the two dataset, data with tweet and data of the city\n",
    "dfcity = pd.read_csv('data_city_update.csv')\n",
    "\n",
    "try:                                                                               #Trying to remove the column 'Unnamed: 0' from the dataframe dfcity. If it fails, it will pass. Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "    dfcity.pop('Unnamed: 0')                                                       #Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "except KeyError as err:\n",
    "        pass\n",
    "\n",
    "to_fast=len(df)                                                                    #if the data contains too many tweets we can access it by reducing the data by modifying len(df) by the number of data we want\n",
    "df_fast = df[:to_fast]\n",
    "\n",
    "i=0                                                                                 #The index of the first element \n",
    "\n",
    "while i<len(df_fast):\n",
    "    try :\n",
    "        if ',' in df_fast.user_location[i]:                             \n",
    "            text =df_fast.user_location[i]\n",
    "            head, sep, tail = text.partition(',')\n",
    "            df_fast.user_location[i]=head                                          #Removing the comma and after from the user_location column\n",
    "\n",
    "    except TypeError as err:                                                       #A way to handle the error. If the program encounters a TypeError, it will pass and continue the program\n",
    "        pass\n",
    "\n",
    "    i+=1                                                                           #add 1 to e to keep the index updated\n",
    "\n",
    "\n",
    "e=0                                                                                #The index of the first element \n",
    "twi=[]                                                                             #creation of an empty list\n",
    "\n",
    "for i in df_fast['user_location']:                                                 #loop that will look at each location of user_location in the tweet data set\n",
    "    \n",
    "    for a in dfcity['city']:                                                       #another loop that will look at each location of city in the dataset of the world city\n",
    "        if i == a:                                                                 #check whether the two elements are the same\n",
    "            twi.append(e)                                                          #if yes, we add e (index element) of the line in data set of tweet\n",
    "    e+=1                                                                           #add 1 to e to keep the index updated\n",
    "    \n",
    "twi = list(set(twi))                                                               #many cities in the world have the same name so we delete duplicate elements\n",
    "twi.sort()                                                                         #It sorts the list of index of the tweet with the correct location\n",
    "\n",
    "nb_tweet_in_data = len(twi)-1                                                      #Taking the last index of the list of the index of the tweet with the correct location\n",
    "df_s = df_fast[:twi[nb_tweet_in_data]]\n",
    "\n",
    "to_drop = [ele for ele in range(len(df_s)) if ele not in twi]                      #we take the inverse of the elements to know which are the elements without corect localization in order to remove them from the data\n",
    "to_drop.sort()\n",
    "\n",
    "for i in (to_drop):                                                                #loop that will drop the line without location in the dataset\n",
    "    df_s=df_s.drop(i)\n",
    "    \n",
    "\n",
    "'''\n",
    "with open(\"listTwi.txt\", \"w\") as f:       #Writing the list of the index of the tweet with the correct location in a txt file\n",
    "    for s in twi:\n",
    "        f.write(str(s) +\",\")\n",
    "'''\n",
    "\n",
    "df_s.to_csv('data_5K.csv')                                                          #Saving the dataframe df_s to a csv file called data_5K.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "### Adding the latitude and longitude for each location for each tweet ###\n",
    "##########################################################################\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data_5K.csv')                #Reading the csv file\n",
    "dfcity = pd.read_csv('data_city_update.csv')   #Reading the csv file\n",
    "\n",
    "try:                                           #Trying to remove the column 'Unnamed: 0' from the dataframe dfcity. If it fails, it will pass. Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "    df.pop('Unnamed: 0')\n",
    "except KeyError as err:\n",
    "        pass\n",
    "\n",
    "e=0                                            ##The index of the first element\n",
    "latitude=[]                                    #creation of an empty list which will be used to indicate the latitude assigned to the city of a tweet\n",
    "longitude=[]                                   #creation of an empty list which will be used to indicate the longitude assigned to the city of a tweet\n",
    "\n",
    "\n",
    "for location in df['user_location']:           #This is a loop that is going through the user_location column of the dataframe df\n",
    "    while location != dfcity.city[e]:          #comparing it to the city column of the dataframe dfcity\n",
    "        e+=1                                   #add 1 to e to keep the index updated\n",
    "    latitude.append(dfcity.lat[e])             #if the while loop stops it means that the right city is found, the latitude and longitude of the city is appended to the latitude and longitude list\n",
    "    longitude.append(dfcity.lng[e])\n",
    "    \n",
    "\n",
    "\n",
    "    e=0                                        #reset the index to 0 as the loop starts again\n",
    "    \n",
    "\n",
    "df.insert(6,\"U_latitude\",latitude,True)        #Inserting the latitude and longitude list into the dataframe df at the 6th and 7th column\n",
    "df.insert(7,\"U_longitude\",longitude,True)\n",
    "\n",
    "\n",
    "df.to_csv('data_tweet_with_location.csv')      #Saving the dataframe df into a csv file called tweet_with_location.csv"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
