{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "### install ###\n",
    "###############\n",
    "'''\n",
    "pip install tweepy\n",
    "pip install pandas\n",
    "pip install xlrd\n",
    "pip install folium\n",
    "pip install vaderSentiment\n",
    "pip install tqdm\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "### import the data from Twitter API ###\n",
    "########################################\n",
    "\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "api_key = 'XXXXX'                                              #put your API keys\n",
    "api_key_secret = 'XXXXXXX'\n",
    "\n",
    "access_token = 'XXXXXX'\n",
    "access_token_secret = 'XXXXX'\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)             # authentication\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "\n",
    "keywords = '#BTC'                                               # search tweets\n",
    "new_search = keywords + \" -filter:retweets\"                     # Exclude retweets in our search\n",
    " \n",
    "date_until = \"\"                                                 # Define until what date we are looking for tweets ex:\"2022-01-01\"  \n",
    "lang = \"en\"                                                     #if we want to filter by language ex :lang = \"en\"\n",
    "\n",
    "limit = 20                                                      #nb of tweets to import\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=new_search, count=100, tweet_mode='extended',until=date_until,lang=lang).items(limit)   #The above code is using the tweepy library to search for tweets using the search term \"new_search\"\n",
    "\n",
    "\n",
    "\n",
    "columns = ['user_name', 'text','date','user_location','user_description','user_followers','user_friends','user_created','user_favourites','source']\n",
    "data = []                                                       #create DataFrame\n",
    "\n",
    "\n",
    "for tweet in tweets:                                            #The above code is appending the information of the tweet to the data list\n",
    "    data.append([tweet.user.screen_name, tweet.full_text, tweet.created_at, tweet.user.location, tweet.user.description,tweet.user.followers_count,tweet.user.friends_count,tweet.user.created_at,tweet.user.favourites_count,tweet.source])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)                        #Creating a dataframe with the data and columns we have defined\n",
    "\n",
    "df.to_csv('data_twitter_api.csv')                               #Saving the dataframe as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "### cleaning of city data, deletion of duplicate city data ###\n",
    "##############################################################\n",
    "\n",
    "import pandas as pd\n",
    "dfcity = pd.read_csv('worldcities.csv')              #Reading the csv file and storing it in a dataframe called dfcity\n",
    "\n",
    "i = 0                                                    #i and e are the indexes of the cities in the dataframe dfcity\n",
    "e = 0\n",
    "to_drop = []                                             #creation of an empty list\n",
    "\n",
    "for city in dfcity['city']:\n",
    "    for city2 in dfcity['city']:\n",
    "        if city == city2 :                               #Comparing the city names in the dataframe dfcity\n",
    "            if i != e :                                  #if the index of the 2 citie with the same name is different\n",
    "                pope = dfcity.population[e]\n",
    "                popi = dfcity.population[i]\n",
    "                \n",
    "                if pope > popi:   \n",
    "                    to_drop.append(i)                    #for these 2 cities with the same name we add the index of the city with the least population to the list \n",
    "                    \n",
    "                elif popi>pope:\n",
    "                    to_drop.append(e)                     #for these 2 cities with the same name we add the index of the city with the least population to the list \n",
    "                    \n",
    "        e += 1                                             #add 1 to e to keep the index updated\n",
    "    i += 1                                                 #add 1 to i to keep the index updated\n",
    "    e = 0                                                  #reset the index to 0 as the loop starts again\n",
    "\n",
    "\n",
    "\n",
    "to_drop = list(set(to_drop))                               #many cities in the world have the same name so we delete duplicate elements\n",
    "to_drop.sort()                                             #It sorts the list in ascending order\n",
    "\n",
    "\n",
    "for i in (to_drop):\n",
    "    dfcity=dfcity.drop(i)                                  #Dropping the cities with the same name and the least population.\n",
    "\n",
    "dfcity.to_csv('data_city_update.csv')                      #Saving the dataframe dfcity in a csv file called data_city_update.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "### delete tweet lines without location ###\n",
    "###########################################\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "low_memory=False\n",
    "df = pd.read_csv('data_twitter_api.csv',engine='python', error_bad_lines=False)   #reading of the two dataset, data with tweet and data of the city\n",
    "dfcity = pd.read_csv('data_city_update.csv')\n",
    "\n",
    "try:                                                                               #Trying to remove the column 'Unnamed: 0' from the dataframe dfcity. If it fails, it will pass. Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "    dfcity.pop('Unnamed: 0')                                                       #Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "except KeyError as err:\n",
    "        pass\n",
    "\n",
    "to_fast=len(df)                                                                    #if the data contains too many tweets we can access it by reducing the data by modifying len(df) by the number of data we want\n",
    "df_fast = df[:to_fast]\n",
    "\n",
    "i=0                                                                                 #The index of the first element \n",
    "\n",
    "while i<len(df_fast):\n",
    "    try :\n",
    "        if ',' in df_fast.user_location[i]:                             \n",
    "            text =df_fast.user_location[i]\n",
    "            head, sep, tail = text.partition(',')\n",
    "            df_fast.user_location[i]=head                                          #Removing the comma and after from the user_location column\n",
    "\n",
    "    except TypeError as err:                                                       #A way to handle the error. If the program encounters a TypeError, it will pass and continue the program\n",
    "        pass\n",
    "\n",
    "    i+=1                                                                           #add 1 to e to keep the index updated\n",
    "\n",
    "\n",
    "e=0                                                                                #The index of the first element \n",
    "twi=[]                                                                             #creation of an empty list\n",
    "\n",
    "for i in df_fast['user_location']:                                                 #loop that will look at each location of user_location in the tweet data set\n",
    "    \n",
    "    for a in dfcity['city']:                                                       #another loop that will look at each location of city in the dataset of the world city\n",
    "        if i == a:                                                                 #check whether the two elements are the same\n",
    "            twi.append(e)                                                          #if yes, we add e (index element) of the line in data set of tweet\n",
    "    e+=1                                                                           #add 1 to e to keep the index updated\n",
    "    \n",
    "twi = list(set(twi))                                                               #many cities in the world have the same name so we delete duplicate elements\n",
    "twi.sort()                                                                         #It sorts the list of index of the tweet with the correct location\n",
    "\n",
    "nb_tweet_in_data = len(twi)-1                                                      #Taking the last index of the list of the index of the tweet with the correct location\n",
    "df_s = df_fast[:twi[nb_tweet_in_data]]\n",
    "\n",
    "to_drop = [ele for ele in range(len(df_s)) if ele not in twi]                      #we take the inverse of the elements to know which are the elements without corect localization in order to remove them from the data\n",
    "to_drop.sort()\n",
    "\n",
    "for i in (to_drop):                                                                #loop that will drop the line without location in the dataset\n",
    "    df_s=df_s.drop(i)\n",
    "    \n",
    "\n",
    "'''\n",
    "with open(\"listTwi.txt\", \"w\") as f:       #Writing the list of the index of the tweet with the correct location in a txt file\n",
    "    for s in twi:\n",
    "        f.write(str(s) +\",\")\n",
    "'''\n",
    "\n",
    "df_s.to_csv('data_5K.csv')                                                          #Saving the dataframe df_s to a csv file called data_5K.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "### Adding the latitude and longitude for each location for each tweet ###\n",
    "##########################################################################\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data_5K.csv')                #Reading the csv file\n",
    "dfcity = pd.read_csv('data_city_update.csv')   #Reading the csv file\n",
    "\n",
    "try:                                           #Trying to remove the column 'Unnamed: 0' from the dataframe dfcity. If it fails, it will pass. Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "    df.pop('Unnamed: 0')\n",
    "except KeyError as err:\n",
    "        pass\n",
    "\n",
    "e=0                                            ##The index of the first element\n",
    "latitude=[]                                    #creation of an empty list which will be used to indicate the latitude assigned to the city of a tweet\n",
    "longitude=[]                                   #creation of an empty list which will be used to indicate the longitude assigned to the city of a tweet\n",
    "\n",
    "\n",
    "for location in df['user_location']:           #This is a loop that is going through the user_location column of the dataframe df\n",
    "    while location != dfcity.city[e]:          #comparing it to the city column of the dataframe dfcity\n",
    "        e+=1                                   #add 1 to e to keep the index updated\n",
    "    latitude.append(dfcity.lat[e])             #if the while loop stops it means that the right city is found, the latitude and longitude of the city is appended to the latitude and longitude list\n",
    "    longitude.append(dfcity.lng[e])\n",
    "    \n",
    "\n",
    "\n",
    "    e=0                                        #reset the index to 0 as the loop starts again\n",
    "    \n",
    "\n",
    "df.insert(6,\"U_latitude\",latitude,True)        #Inserting the latitude and longitude list into the dataframe df at the 6th and 7th column\n",
    "df.insert(7,\"U_longitude\",longitude,True)\n",
    "\n",
    "\n",
    "df.to_csv('data_tweet_with_location.csv')      #Saving the dataframe df into a csv file called tweet_with_location.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "### Converting the date and time from excel format to datetime format ###\n",
    "#########################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "\n",
    "df = pd.read_csv('data_tweet_with_location.csv') \n",
    "\n",
    "try:                                                            #Trying to remove the column 'Unnamed: 0' from the dataframe dfcity. If it fails, it will pass. Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "    df.pop('Unnamed: 0')\n",
    "except KeyError as err:\n",
    "        pass\n",
    "\n",
    "### not useful using Twitter API ###\n",
    "'''\n",
    "a=0                                                             #The index of the first element\n",
    "while a < len(df):                                              #The above code is converting the date and time from excel format to datetime format\n",
    "    try:\n",
    "        user_created_date = xlrd.xldate_as_datetime(df.user_created[a], 0)\n",
    "        df.user_created[a]=user_created_date\n",
    "        tweet_date = xlrd.xldate_as_datetime(df.date[a], 0)\n",
    "        df.date[a]=tweet_date\n",
    "    except TypeError as err:\n",
    "        pass\n",
    "    \n",
    "    a+=1                                                         #add 1 to e to keep the index updated\n",
    "\n",
    "'''\n",
    "\n",
    "df.to_csv('data_tweet_with_location_and_date.csv')               #Saving the dataframe df to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "######## extract the hour from the date ##########\n",
    "### extract the tweet link from the tweet text ###\n",
    "##################################################\n",
    "\n",
    "df = pd.read_csv('data_tweet_with_location_and_date.csv') \n",
    "\n",
    "try:                                                    #Trying to remove the column 'Unnamed: 0' from the dataframe dfcity. If it fails, it will pass. Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "    df.pop('Unnamed: 0')\n",
    "except KeyError as err:\n",
    "        pass\n",
    "\n",
    "hour = []                                               #Creating empty lists to store data \n",
    "date = []\n",
    "tweet = []\n",
    "link = []\n",
    "\n",
    "i=0                                                      #The index of the first element\n",
    "while i < len(df):\n",
    "    date_hour =df.date[i]\n",
    "    head, sep, tail = date_hour.partition(' ')          #Splitting the string date_hour into three parts: head wich corespond to the date, sep and tail which corresponds to the hour. The separator is the space ' '\n",
    "    date.append(head)                                   #appends the date to the date list\n",
    "    head, sep, tail=tail.partition('+')                 #It splits the string tail into three parts: head wich corespond to the hour, sep and tail which corresponds to the time zone wich is which is incorrect information. The separator is the '+'\n",
    "    hour.append(head)                                   #It appends the hour to the hour list                         \n",
    "\n",
    "    tw =df.text[i]                                      #Creating a variable tw which is equal to the text of the tweet at the index i\n",
    "    \n",
    "    head, sep, tail = tw.partition('https://t.co/')     #It splits the string tw into three parts: head wich corespond to the text of the tweet, sep and tail which corresponds to the link. The separator is the 'https://t.co/'\n",
    "    \n",
    "  \n",
    "    \n",
    "    while 'https://t.co/' in tail :                         #Checking if there is stil a link in the tail of the tweet text. If there is this means that there is a link in the tweet before the twitter link of the tweet itself\n",
    "        lk = tail\n",
    "        head2, sep, tail = lk.partition('https://t.co/')\n",
    "    \n",
    "    if 'https://t.co/' in tail :                            #if there is a link before the Twitter link of the tweet we add head2 to the tweet\n",
    "        tweet.append(head+head2)                            #It appends the text of the tweet to the tweet list\n",
    "    else :                                                  #if there is only one link \n",
    "        tweet.append(head)                                  #It appends the text of the tweet to the tweet list\n",
    "    \n",
    "   \n",
    "    \n",
    "    link.append(sep+tail)                               #It appends the link to the link list\n",
    "    \n",
    "    i+=1                                                #add 1 to e to keep the index updated\n",
    "\n",
    "\n",
    "\n",
    "df.pop('date')                                          #Removing the column old 'date'\n",
    "df.insert(10,\"date\",date,True)                          #inserting the new columns 'date' and 'hour' from the list at the index 10 and 11\n",
    "df.insert(11,\"hour\",hour,True)\n",
    "df.pop('text')                                          #Removing the column old 'text'\n",
    "df.insert(12,\"tweet\",tweet,True)                        #Inserting the new columns 'tweet' and 'link' from the list at the index 12 and 13\n",
    "df.insert(13,\"link\",link,True)\n",
    "\n",
    "df.to_csv('data_tweet_with_location_and_date_hour.csv')  #Saving the dataframe df into a csv file called 'data_tweet_with_location_and_date_hour.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "### development of sentimental analysis ###\n",
    "###########################################\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv('data_tweet_with_location_and_date_hour.csv') \n",
    "\n",
    "try:                                                    #Trying to remove the column 'Unnamed: 0' from the dataframe dfcity. If it fails, it will pass. Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "    df.pop('Unnamed: 0')\n",
    "except KeyError as err:\n",
    "        pass\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()                  #Creating an object of the class SentimentIntensityAnalyzer\n",
    "\n",
    "sentiment = []                                            #Creating an empty list\n",
    "\n",
    "\n",
    "for i,s in enumerate(tqdm(df['tweet'],position=0, leave=True)):     #A for loop that iterates over the column 'tweet' \n",
    "    vs = analyzer.polarity_scores(str(s))                           #Creating a dictionary with the sentiment of the tweet\n",
    "    sentiment.append(vs[\"compound\"])                                ##Appending the value of the key 'compound' of the dictionary vs to the list sentiment\n",
    "\n",
    "df[\"sentiment\"] = sentiment                                 ##Creating a new column in the dataframe df called 'sentiment' and it is filling it with the values of the list sentiment\n",
    "\n",
    "df.to_csv('data_sentimental.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "### creation and display of the map ###\n",
    "#######################################\n",
    "\n",
    "import folium\n",
    "import pandas as pd\n",
    "import random \n",
    "from folium import plugins\n",
    "from folium import LayerControl\n",
    "from folium import TileLayer\n",
    "from folium.plugins import MeasureControl \n",
    "from folium.plugins import Fullscreen\n",
    "from folium.plugins import HeatMap\n",
    "from folium.plugins import Terminator\n",
    "\n",
    "df = pd.read_csv('data_sentimental.csv')                        #Reading the csv file and storing it in a dataframe\n",
    "\n",
    "try:                                                                                  #Trying to remove the column 'Unnamed: 0' from the dataframe dfcity. If it fails, it will pass. Because pd.read_csv creates a column 'Unnamed: 0'\n",
    "    df.pop('Unnamed: 0')\n",
    "except KeyError as err:\n",
    "        pass\n",
    "\n",
    "'''create a title'''\n",
    "loc = 'Tweet about Bitcoin'                                                            #The title of the map\n",
    "title_html = '''<h3 align=\"center\" style=\"font-size:16px\"><b>{}</h3>'''.format(loc)   \n",
    "\n",
    "#qf = folium.Figure(width=1000, height=1000)                                            #Creating a figure with a width and height of 1000 pixels\n",
    "m = folium.Map(location=[0, 0], zoom_start=2, control_scale=True)#.add_to(f)            #Creating a map \n",
    "\n",
    "m.get_root().html.add_child(folium.Element(title_html))                                #Adding the title to the map\n",
    "\n",
    "m.add_child(MeasureControl())                                                          #Adding a measure control to the map\n",
    "\n",
    "#nbTweet=int(input())                                                                  #Asking the user to input a number\n",
    "nbTweet=25\n",
    "\n",
    "displayTweet = random.sample(range(0, len(df)),nbTweet)                               #Creating a list of random numbers between 0 and the number of rows in the dataframe.\n",
    "\n",
    "color = 'blue'                                                                        #The color of the marker\n",
    "colorNeg= 'red'\n",
    "colorPos='green'\n",
    "'''lightgray', 'darkred', 'blue', 'pink', 'gray', 'red', 'orange', 'lightgreen', 'white', 'beige', 'darkblue', 'green', 'cadetblue', 'darkpurple', 'purple', 'lightblue', 'lightred', 'darkgreen', 'black'''\n",
    "\n",
    "tooltipNeg = \"View Negative tweet!\"\n",
    "tooltipPos = \"View Positive tweet!\"\n",
    "tooltip = \"View Neutral tweet!\"\n",
    "\n",
    "def popup_html(row):                                                                  #Creating a function that will be used to create the popups\n",
    "    a = row\n",
    "    name=df.user_name[a]                                                              #Creating a variable for column in the dataframe\n",
    "    tweet=df.tweet[a]\n",
    "    followers=df.user_followers[a]\n",
    "    date=df.date[a] \n",
    "    hour=df.hour[a]                                                                   #The UTC datetime that the List was created on Twitter\n",
    "    link=df.link[a]\n",
    "\n",
    "    left_col_color = \"#3498DB\"                                                        #Setting the color of the left and right column of the table in the popup\n",
    "    right_col_color = \"#E1E8ED\"\n",
    "    \n",
    "    #CreatinCreating a table with the tweet, link, followers, date and the hour\n",
    "    #the html code for the popup\n",
    "    html = \"\"\"<!DOCTYPE html>\n",
    "    <html>\n",
    "    <h5 style=\"margin-bottom:0\";margin-top: 0; width=\"10px\">{}</h5>\"\"\".format(name) + \"\"\"\n",
    "        <table style=\"height: 100px; width: 250px;\">\n",
    "    <tbody>\n",
    "    <tr>\n",
    "    <td style=\"background-color: \"\"\"+ left_col_color +\"\"\";\"><span style=\"color: #ffffff;\">Tweet<br><a href={} target=\"_blank\" style=\"color:#FFC565;\">Link</a></td>\"\"\".format(link) + \"\"\"</span></td>\n",
    "    <td style=\"width: 150px;background-color: \"\"\"+ right_col_color +\"\"\";\">{}</td>\"\"\".format(tweet) + \"\"\"\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"background-color: \"\"\"+ left_col_color +\"\"\";\"><span style=\"color: #ffffff;\">Followers</span></td>\n",
    "    <td style=\"width: 150px;background-color: \"\"\"+ right_col_color +\"\"\";\">{}</td>\"\"\".format(followers) + \"\"\"\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"background-color: \"\"\"+ left_col_color +\"\"\";\"><span style=\"color: #ffffff;\">Date</span></td>\n",
    "    <td style=\"width: 150px;background-color: \"\"\"+ right_col_color +\"\"\";\">{}</td>\"\"\".format(date) + \"\"\"\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"background-color: \"\"\"+ left_col_color +\"\"\";\"><span style=\"color: #ffffff;\">Hour (UTC)</span></td>\n",
    "    <td style=\"width: 150px;background-color: \"\"\"+ right_col_color +\"\"\";\">{}</td>\"\"\".format(hour) + \"\"\"\n",
    "    </tr>\n",
    "    </tbody>\n",
    "    </table>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return html\n",
    "\n",
    "\n",
    "i=0\n",
    "while i < nbTweet :                                                                     #This is a while loop that will run until i is equal to nbTweet\n",
    "    html = popup_html(displayTweet[i])                                                  #using the html created in the function popup_html\n",
    "    size= min(max(200,len(str(df.tweet[displayTweet[i]]))*2.2),400)                     #definition of the size of the popup (min = 200, max=400) which takes into account the size of the tweet to display\n",
    "    iframe = folium.IFrame(html,width=260,height=size)\n",
    "    popup = folium.Popup(iframe,max_width=300)\n",
    "    #print(df.sentiment[displayTweet[i]])\n",
    "    if df.sentiment[displayTweet[i]]< -0.1:\n",
    "        marker = folium.Marker([df.U_latitude[displayTweet[i]], df.U_longitude[displayTweet[i]]],popup=popup,icon=folium.Icon(color=colorNeg, icon='twitter', prefix='fa'),tooltip =tooltipNeg).add_to(m)        #creating and adding the marker with popup to the map\n",
    "    \n",
    "    elif df.sentiment[displayTweet[i]]> 0.1:\n",
    "        marker = folium.Marker([df.U_latitude[displayTweet[i]], df.U_longitude[displayTweet[i]]],popup=popup,icon=folium.Icon(color=colorPos, icon='twitter', prefix='fa'),tooltip =tooltipPos).add_to(m)        #creating and adding the marker with popup to the map\n",
    "    else :\n",
    "        marker = folium.Marker([df.U_latitude[displayTweet[i]], df.U_longitude[displayTweet[i]]],popup=popup,icon=folium.Icon(color=color, icon='twitter', prefix='fa'),tooltip =tooltip).add_to(m)        #creating and adding the marker with popup to the map\n",
    "\n",
    "    i+=1                                                                                 #add 1 to e to keep the index updated\n",
    "\n",
    "'''Creating a heat map of the tweets'''\n",
    "df.U_latitude=df.U_latitude.astype(float)                                                #Converting the latitude and longitude to float\n",
    "df.U_longitude=df.U_longitude.astype(float)\n",
    "heat_df=df[[\"U_latitude\",\"U_longitude\"]]                                                 #Creating a dataframe with only the columns U_latitude and U_longitude\n",
    "heat_data=list(zip(df.U_latitude, df.U_longitude))                                       #Creating a list of tuples with the latitude and longitude\n",
    "HeatMap(heat_data).add_to(folium.FeatureGroup(name='Heat Map',overlay=True, control=True, show=False).add_to(m))       #Creating and adding the heat map of the tweets to the map\n",
    "\n",
    "'''Add dark and light mode '''\n",
    "TileLayer(tiles='cartodbdark_matter',name=\"dark mode\", opacity=0.8,control=True,show=True).add_to(m)     #Adding a dark mode to the map\n",
    "TileLayer(tiles='cartodbpositron',name=\"light mode\", opacity=0.8,control=True,show=True).add_to(m)\n",
    "TileLayer(tiles='OpenStreetMap', opacity=0.7,control=True,show=True).add_to(m)\n",
    "\n",
    "Terminator().add_to(folium.FeatureGroup(name='Day/Night',overlay=True, control=True, show=False).add_to(m))    #shows day and night which can be interesting with very recent tweets\n",
    "\n",
    "'''Add a layer controller'''\n",
    "#folium.LayerControl(collapsed=False).add_to(m)\n",
    "LayerControl(position='topright', collapsed=False, autoZIndex=True, sortLayers=False).add_to(m)          #Adding a layer controller to the map\n",
    "\n",
    "Fullscreen(position=\"topright\",title=\"Expand me\",title_cancel=\"Exit me\",force_separate_button=True,).add_to(m) #Adding a fullscreen button to the map\n",
    "\n",
    "\n",
    "'''Add a minimap'''\n",
    "minimap = plugins.MiniMap()                                                                 #Adding a minimap to the map\n",
    "m.add_child(minimap)\n",
    "\n",
    "\n",
    "m.save('map-twiter.html')                                                                   #Saving the map as an html file\n",
    "\n",
    "m                                                                                           #Display m, the map that we created\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
